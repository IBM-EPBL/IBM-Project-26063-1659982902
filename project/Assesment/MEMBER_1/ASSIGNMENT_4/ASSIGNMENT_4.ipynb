{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAdbgMCynXZL"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"private_outputs\": true,\n",
        "      \"provenance\": [],\n",
        "      \"toc_visible\": true\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"xPmjSeP6ztWI\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"import pandas as pd \\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"from sklearn.model_selection import train_test_split\\n\",\n",
        "        \"from sklearn.preprocessing import LabelEncoder\\n\",\n",
        "        \"from keras.models import Model\\n\",\n",
        "        \"from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\\n\",\n",
        "        \"from keras.optimizers import RMSprop\\n\",\n",
        "        \"from keras.preprocessing.text import Tokenizer\\n\",\n",
        "        \"from keras_preprocessing import sequence\\n\",\n",
        "        \"from keras.utils import to_categorical\\n\",\n",
        "        \"from keras.models import load_model\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"import csv\\n\",\n",
        "        \"import tensorflow as tf\\n\",\n",
        "        \"import pandas as pd\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"import matplotlib.pyplot as plt\\n\",\n",
        "        \"from tensorflow.keras.preprocessing.text import Tokenizer\\n\",\n",
        "        \"from tensorflow.keras.preprocessing.sequence import pad_sequences\\n\",\n",
        "        \"import nltk\\n\",\n",
        "        \"nltk.download('stopwords')  \\n\",\n",
        "        \"from nltk.corpus import stopwords\\n\",\n",
        "        \"STOPWORDS = set(stopwords.words('english'))\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"Gn4V67q0z0eT\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"from google.colab import drive\\n\",\n",
        "        \"drive.mount('/content/drive')\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"E9MGSQZNz6Qp\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"cd/content/drive/MyDrive/Colab Notebooks\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"3e8BhX8m0Dyf\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"df = pd.read_csv('/content/drive/MyDrive/spam.csv',delimiter=',',encoding='latin-1')\\n\",\n",
        "        \"df.head()\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"635W4rCX0Lg5\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"df.drop(['Unnamed: 2','Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True) \\n\",\n",
        "        \"df.info()\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"JZ69G7O24Zsg\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"df.groupby(['v1']).size()\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"F47AuS5v4e2X\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"#Label Encoding Required Column\\n\",\n",
        "        \"X = df.v2\\n\",\n",
        "        \"Y = df.v1\\n\",\n",
        "        \"le = LabelEncoder()\\n\",\n",
        "        \"Y = le.fit_transform(Y)\\n\",\n",
        "        \"Y = Y.reshape(-1,1)\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"n46sH3zT4ieg\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"# Test and train data split \\n\",\n",
        "        \"X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"jQ1vSLxw4mbB\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"# Tokenisation function\\n\",\n",
        "        \"max_words = 1000\\n\",\n",
        "        \"max_len = 150\\n\",\n",
        "        \"tok = Tokenizer(num_words=max_words)\\n\",\n",
        "        \"tok.fit_on_texts(X_train)\\n\",\n",
        "        \"sequences = tok.texts_to_sequences(X_train)\\n\",\n",
        "        \"sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"EouGpOLE4pt-\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"\\n\",\n",
        "        \"#LSTM model\\n\",\n",
        "        \"inputs = Input(name='InputLayer',shape=[max_len])\\n\",\n",
        "        \"layer = Embedding(max_words,50,input_length=max_len)(inputs)\\n\",\n",
        "        \"layer = LSTM(64)(layer)\\n\",\n",
        "        \"layer = Dense(256,name='FullyConnectedLayer1')(layer)\\n\",\n",
        "        \"layer = Activation('relu')(layer)\\n\",\n",
        "        \"layer = Dropout(0.5)(layer)\\n\",\n",
        "        \"layer = Dense(1,name='OutputLayer')(layer)\\n\",\n",
        "        \"layer = Activation('sigmoid')(layer)\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"iiDknBZl4tNi\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"model = Model(inputs=inputs,outputs=layer)\\n\",\n",
        "        \"model.summary()\\n\",\n",
        "        \"model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"dV2l69IR4wqU\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,validation_split=0.2)\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"hLG5kG4240AO\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"model.save(\\\"Ai_Spam_Identifier\\\")\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"Tg4RnViS5WJp\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"test_sequences = tok.texts_to_sequences(X_test)\\n\",\n",
        "        \"test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"NfRE9Xky5oq7\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"accuracy = model.evaluate(test_sequences_matrix,Y_test)\\n\",\n",
        "        \"print('Accuracy: {:0.3f}'.format(accuracy[1]))\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"MmkiG2Ms5syq\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"y_pred = model.predict(test_sequences_matrix)\\n\",\n",
        "        \"print(y_pred[25:40].round(3))\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"hF_RFQt95zC9\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"print(Y_test[25:40])\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"puWIeYkr58Xb\"\n",
        "      },\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    }
  ]
}